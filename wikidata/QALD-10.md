---
    name: QALD-10
    datasetUrl: https://github.com/KGQA/QALD-10
---

|       Model / System       |     Year     |   Precision   |    Recall     |      F1       |                            Language                             |                              Reported by                               |
|:--------------------------:|:------------:|:-------------:|:-------------:|:-------------:|:---------------------------------------------------------------:|:----------------------------------------------------------------------:|
| Borroto et al. (SPARQL-QA) |     2022     | 45.38 (Macro) | 45.74 (Macro) | 59.47 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205200035) | 
|          QAnswer           |     2022     | 50.68 (Macro) | 52.38 (Macro) | 57.76 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205120000) |
| TSET-Base |     2024     |  |  | 51.37 |                               EN                                | [Qi et. al.](https://www.mdpi.com/2076-3417/14/4/1521) |
|      Steinmetz et al.      |     2022     | 32.06 (Macro) | 33.12 (Macro) | 49.09 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205260012) |
| TSET-Small |     2024     |  |  | 47.15 |                               EN                                | [Qi et. al.](https://www.mdpi.com/2076-3417/14/4/1521) |
|      Baramiia et al.       |     2022     | 42.89 (Macro) | 42.72 (Macro) | 42.81 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205210032) |
|      Gavrilev et al.       |     2022     | 14.21 (Macro) | 14.00 (Macro) | 19.48 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205210032) |
| EffiQA w/Deepseek-V2       | 2024  |  50.2  |       -       |       -       |    -          |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|      EffiQA w/ChatGPT      | 2024  |  46.2  |       -       |       -       |       -       |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             | 
|       EffiQA w/GPT-4       | 2024  |  51.4  |       -       |       -       |       -       |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|       Prior FT SOTA        | 2024  |  45.4  |       -       |       -       |       -       |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|    Prior Prompting SOTA    | 2024  |   -    |       -       |       -       |       -       |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
| Prior tight-coupling SOTA  | 2024  |  54.7  |       -       |       -       |       -       |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|        SC w/ChatGPT        | 2024  |  45.3  |       -       |       -       |       -       |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|       CoT w/ChatGPT        | 2024  |  42.9  |       -       |       -       |       -       |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|    IO prompt w/ChatGPT     | 2024  |  42.0  |       -       |       -       |       -       |    EN    |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |