---
    name: QALD-10
    datasetUrl: https://github.com/KGQA/QALD-10
---

|       Model / System       | Year | Hits@1 |   Precision   |    Recall     |      F1       |                            Language                             |                              Reported by                               |
|:--------------------------:|:----:|:------:|:-------------:|:-------------:|:-------------:|:---------------------------------------------------------------:|:----------------------------------------------------------------------:|
| Borroto et al. (SPARQL-QA) | 2022 |   -    | 45.38 (Macro) | 45.74 (Macro) | 59.47 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205200035) | 
|          QAnswer           | 2022 |   -    | 50.68 (Macro) | 52.38 (Macro) | 57.76 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205120000) |
|      Steinmetz et al.      | 2022 |   -    | 32.06 (Macro) | 33.12 (Macro) | 49.09 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205260012) |
|      Baramiia et al.       | 2022 |   -    | 42.89 (Macro) | 42.72 (Macro) | 42.81 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205210032) |
|      Gavrilev et al.       | 2022 |   -    | 14.21 (Macro) | 14.00 (Macro) | 19.48 (Macro) |                               EN                                | [GERBIL](https://gerbil-qa.aksw.org/gerbil/experiment?id=202205210032) |
|    IO prompt w/ChatGPT     | 2024 |  42.0  |       -       |       -       |       -       |                               EN                                |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|    CoT prompt w/ChatGPT    | 2024 |  42.9  |       -       |       -       |       -       |                               EN                                |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|    SC prompt w/ChatGPT     | 2024 |  45.3  |       -       |       -       |       -       |                               EN                                |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|       Prior FT SOTA        | 2024 |  45.4  |       -       |       -       |       -       |                               EN                                |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|      EffiQA w/ChatGPT      | 2024 |  46.2  |       -       |       -       |       -       |                               EN                                |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|    EffiQA w/Deepseek-V2    | 2024 |  50.2  |       -       |       -       |       -       |                               EN                                |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|        EffiQA w/GPT-4        | 2024 |  51.4  |       -       |       -       |       -       |                               EN                                |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
|  Prior tigh-coupling SOTA  | 2024 |  54.7  |       -       |       -       |       -       |                               EN                                |            [Dong et al.](https://arxiv.org/pdf/2406.01238)             |
