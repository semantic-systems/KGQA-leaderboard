---
    name: GraphQuestions
    datasetUrl: https://github.com/ysu1989/GraphQuestions
---

|          Model / System           | Year | Accuracy |   F1   |   Hit@1   |   Hit@3   |   Hit@10   |                        Reported by                        |
|:---------------------------------:|:----:|:--------:|:------:|:---------:|:---------:|:----------:|:---------------------------------------------------------:|
| ChatGPT                           | 2023 |  53.10   |     -  | -         | -         | -          | [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)        |
| GPT-3.5v3                         | 2023 |  47.95   |     -  | -         | -         | -          | [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)        |
| TIARA + GAIN (T5-3B)              | 2023 |    -     |  48.7  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| TIARA + GAIN (T5-base)            | 2023 |    -     |  45.5  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| GPT-3.5v2                         | 2023 |  40.85   |     -  | -         | -         | -          | [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)        |
| KB-BINDER                         | 2023 |    -     |  39.5  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| GPT-3                             | 2023 |  38.32   |     -  | -         | -         | -          | [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)        |
| TIARA (T5-base)                   | 2023 |    -     |  37.9  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| FLAN-T5                           | 2023 |  32.27   |     -  | -         | -         | -          | [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)        |
| ArcaneQA                          | 2023 |    -     |  31.8  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| BERT + Ranking                    | 2023 |    -     |  25.0  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| SPARQA                            | 2023 |    -     |  21.5  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| PARA4QA                           | 2023 |    -     |  20.4  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| UDepLambda                        | 2023 |    -     |  17.7  | -         | -         | -          | [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
| LGOT                              | 2024 |    -     |     -  | 100.0     | 100.0     | 100.0      | [Liu et al.](https://arxiv.org/pdf/2404.04264)            |
| QTO                               | 2024 |    -     |     -  | 100.0     | 100.0     | 100.0      | [Liu et al.](https://arxiv.org/pdf/2404.04264)            |
| LGOT     (50% KG)                 | 2024 |    -     |     -  | 52.2      | 52.8      | 52.8       | [Liu et al.](https://arxiv.org/pdf/2404.04264)            |
| ChatGPT  (50% KG)                 | 2024 |    -     |     -  | 28.8      | 30.3      | 33.3       | [Liu et al.](https://arxiv.org/pdf/2404.04264)            |
| QTO      (50% KG)                 | 2024 |    -     |     -  | 26.8      | 26.8      | 26.8       | [Liu et al.](https://arxiv.org/pdf/2404.04264)            |
| CoT                               | 2024 |    -     |     -  | 18.7      | 19.4      | 19.4       | [Liu et al.](https://arxiv.org/pdf/2404.04264)            |
| CoT      (50% KG)                 | 2024 |    -     |     -  | 18.7      | 19.4      | 19.4       | [Liu et al.](https://arxiv.org/pdf/2404.04264)            |
| ChatGPT                           | 2024 |    -     |     -  | 18.4      | 19.0      | 21.5       | [Liu et al.](https://arxiv.org/pdf/2404.04264)            |